{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional-mnist-tensorflow-go-inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "MqMPpMVZCni8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 0. Introduction"
      ]
    },
    {
      "metadata": {
        "id": "znLvjOM3Cni9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQqI5W0UCnjB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example based on: Deep Learning with Python by Francois Chollet:\n",
        "https://www.manning.com/books/deep-learning-with-python"
      ]
    },
    {
      "metadata": {
        "id": "o6gYEfDeCnjC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HgVfLtHkCnjE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Load data"
      ]
    },
    {
      "metadata": {
        "id": "38sIZkHnCnjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The MNIST database of handwritten digit has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
      ]
    },
    {
      "metadata": {
        "id": "Gv05T42HInn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf myModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLgRn4rGCnjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "86ae6817-ef6e-41dc-ef8f-f32c656cf988"
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow.models import mnist\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def weight_variable(shape):\n",
        "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "def bias_variable(shape):\n",
        "    initial = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(initial)\n",
        "\n",
        "\n",
        "def conv2d(x, W, name=None):\n",
        "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
        "\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                          strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def conv_layer(input, shape, name=None):\n",
        "    W = weight_variable(shape)\n",
        "    b = bias_variable([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input, W, name=name) + b)\n",
        "\n",
        "\n",
        "def full_layer(input, size, name=None):\n",
        "    in_size = int(input.get_shape()[1])\n",
        "    W = weight_variable([in_size, size])\n",
        "    b = bias_variable([size])\n",
        "    return tf.matmul(input, W, name=name) + b\n",
        "\n",
        "DATA_DIR = '/tmp/data'\n",
        "MINIBATCH_SIZE = 50\n",
        "STEPS = 5000\n",
        "\n",
        "\n",
        "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "conv1 = conv_layer(x_image, shape=[5, 5, 1, 32], name=\"inputLayer\")\n",
        "conv1_pool = max_pool_2x2(conv1)\n",
        "\n",
        "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
        "conv2_pool = max_pool_2x2(conv2)\n",
        "\n",
        "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n",
        "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
        "\n",
        "y_conv = full_layer(full1_drop, 10, name=\"inferenceLayer\")\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y_))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for i in range(STEPS):\n",
        "        batch = mnist.train.next_batch(MINIBATCH_SIZE)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0], y_: batch[1],\n",
        "                                                           keep_prob: 1.0})\n",
        "            print(\"step {}, training accuracy {}\".format(i, train_accuracy))\n",
        "\n",
        "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
        "\n",
        "    X = mnist.test.images.reshape(10, 1000, 784)\n",
        "    Y = mnist.test.labels.reshape(10, 1000, 10)\n",
        "    test_accuracy = np.mean(\n",
        "        [sess.run(accuracy, feed_dict={x: X[i], y_: Y[i], keep_prob: 1.0}) for i in range(10)])\n",
        "    builder = tf.saved_model.builder.SavedModelBuilder(\"myModel\")\n",
        "    builder.add_meta_graph_and_variables(sess,\n",
        "                                  [\"myTag\"]\n",
        "                                  \n",
        "                                  )\n",
        "    builder.save()\n",
        "\n",
        "print(\"test accuracy: {}\".format(test_accuracy))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "step 0, training accuracy 0.07999999821186066\n",
            "step 100, training accuracy 0.8199999928474426\n",
            "step 200, training accuracy 0.9599999785423279\n",
            "step 300, training accuracy 0.9399999976158142\n",
            "step 400, training accuracy 0.9599999785423279\n",
            "step 500, training accuracy 0.9399999976158142\n",
            "step 600, training accuracy 0.9399999976158142\n",
            "step 700, training accuracy 0.9800000190734863\n",
            "step 800, training accuracy 0.9200000166893005\n",
            "step 900, training accuracy 0.9800000190734863\n",
            "step 1000, training accuracy 0.9800000190734863\n",
            "step 1100, training accuracy 0.9800000190734863\n",
            "step 1200, training accuracy 0.9800000190734863\n",
            "step 1300, training accuracy 1.0\n",
            "step 1400, training accuracy 0.9800000190734863\n",
            "step 1500, training accuracy 1.0\n",
            "step 1600, training accuracy 0.9800000190734863\n",
            "step 1700, training accuracy 1.0\n",
            "step 1800, training accuracy 0.9800000190734863\n",
            "step 1900, training accuracy 0.9800000190734863\n",
            "step 2000, training accuracy 0.9599999785423279\n",
            "step 2100, training accuracy 0.9800000190734863\n",
            "step 2200, training accuracy 1.0\n",
            "step 2300, training accuracy 0.9800000190734863\n",
            "step 2400, training accuracy 0.9800000190734863\n",
            "step 2500, training accuracy 1.0\n",
            "step 2600, training accuracy 0.9800000190734863\n",
            "step 2700, training accuracy 0.9800000190734863\n",
            "step 2800, training accuracy 1.0\n",
            "step 2900, training accuracy 0.9800000190734863\n",
            "step 3000, training accuracy 1.0\n",
            "step 3100, training accuracy 0.9800000190734863\n",
            "step 3200, training accuracy 0.9800000190734863\n",
            "step 3300, training accuracy 1.0\n",
            "step 3400, training accuracy 0.9599999785423279\n",
            "step 3500, training accuracy 0.9800000190734863\n",
            "step 3600, training accuracy 1.0\n",
            "step 3700, training accuracy 1.0\n",
            "step 3800, training accuracy 1.0\n",
            "step 3900, training accuracy 0.9800000190734863\n",
            "step 4000, training accuracy 1.0\n",
            "step 4100, training accuracy 1.0\n",
            "step 4200, training accuracy 1.0\n",
            "step 4300, training accuracy 0.9599999785423279\n",
            "step 4400, training accuracy 1.0\n",
            "step 4500, training accuracy 0.9800000190734863\n",
            "step 4600, training accuracy 0.9599999785423279\n",
            "step 4700, training accuracy 0.9800000190734863\n",
            "step 4800, training accuracy 1.0\n",
            "step 4900, training accuracy 1.0\n",
            "INFO:tensorflow:No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: myModel/saved_model.pb\n",
            "test accuracy: 0.9880000352859497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AHj5lHhMJXKZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ba50ee4-e1f5-47bc-faef-2848a8bcca31"
      },
      "cell_type": "code",
      "source": [
        "! ls -l myModel"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 220\n",
            "-rw-r--r-- 1 root root 220698 Jan 23 09:56 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Jan 23 09:56 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ObdeXIHJJqAM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4a43050f-682d-4220-d559-5ed567ac410c"
      },
      "cell_type": "code",
      "source": [
        "!ls -l myModel/variables"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 115128\n",
            "-rw-r--r-- 1 root root 117886848 Jan 23 09:56 variables.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root      2559 Jan 23 09:56 variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xz6GsUryCnjJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Inspect data"
      ]
    },
    {
      "metadata": {
        "id": "-hjqtVjSCnjJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try to get a feel for the data you are using to train and test your neural network. "
      ]
    },
    {
      "metadata": {
        "id": "fapJtoLvCnjK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training data"
      ]
    },
    {
      "metadata": {
        "id": "Hf5hXexJCnjL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Training data will be used to train our neural network to recognize hand-written digits.\n",
        "- MNIST provides 60000 labeled training images, each 28x28 pixels"
      ]
    },
    {
      "metadata": {
        "id": "iIeg8zxHCnjM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5dcS4HdCnjN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lA7CYDK8CnjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_image(images, labels, index):\n",
        "    img = images[index].reshape((28,28))\n",
        "    label = labels[index]\n",
        "    plt.imshow(img)\n",
        "    plt.title(label)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HlW4FwjJCnjT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_image(train_images, train_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Tp1iUQoCnjU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test data"
      ]
    },
    {
      "metadata": {
        "id": "FXW5XtY7CnjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Test data will be used to validate how good our network performs on data it has never seen.\n",
        "- MNIST provides 10000 test images, each 28x28.\n",
        "- It's important to note that these should never be used in the training cycle. A 'test set' should never contain images the network has already seen during training. (read more: [Model Selection and Train/Validation/Test Sets](https://www.coursera.org/lecture/machine-learning/model-selection-and-train-validation-test-sets-QGKbr) and [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/))"
      ]
    },
    {
      "metadata": {
        "id": "Z2HOhZmyCnjW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3p0VVLMyCnjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "olSKV_qDCnja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_image(test_images, test_labels, 168)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l2MLxuATCnjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Network architecture"
      ]
    },
    {
      "metadata": {
        "id": "Feg9Vq7nCnjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1. ConvNet (Feature extraction)"
      ]
    },
    {
      "metadata": {
        "id": "sIOjJQJoCnje",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the network architecture that will be used for training\n",
        "\n",
        "- how many layers \n",
        "- which type of layer\n",
        "    - Convolution: #channels, kernel size, activation\n",
        "    - MaxPool: matrix size\n",
        "\n",
        "Important: ConvNets take as input tensors of shape: (image_height, image_width, channels)\n",
        "\n",
        "**Note:**\n",
        "\n",
        "Convolutional layers learn local patterns (features that can appear anywhere in the image)\n",
        "\n",
        "Dense layers learn global patterns."
      ]
    },
    {
      "metadata": {
        "id": "2lxGWhPqCnjf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))\n",
        "network.add(layers.MaxPool2D((2, 2)))\n",
        "network.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "network.add(layers.MaxPool2D((2, 2)))\n",
        "network.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmL63YMdCnjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "skUA8soGCnji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2. Classifier layer"
      ]
    },
    {
      "metadata": {
        "id": "V8_WMAHJCnjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.add(layers.Flatten())\n",
        "network.add(layers.Dense(64, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ss479k73Cnjn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "be3t6BCXCnjr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Compilation Step"
      ]
    },
    {
      "metadata": {
        "id": "WBUsm3wLCnjt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the compilation step we define the:\n",
        "\n",
        "- the loss function\n",
        "- the optimizer\n",
        "- the evaluation metric"
      ]
    },
    {
      "metadata": {
        "id": "9Uiep3sgCnjt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "               loss='categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfYFdjB-Cnjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Data Preparation"
      ]
    },
    {
      "metadata": {
        "id": "bPd1GP5pCnjx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before feeding the data into the network for training, we make sure it is formatted properly."
      ]
    },
    {
      "metadata": {
        "id": "01mawG2NCnjy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the images"
      ]
    },
    {
      "metadata": {
        "id": "Yc9IW3IfCnjz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_reshaped = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images_reshaped = test_images.reshape((10000, 28, 28, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2EPYT2kCnj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_reshaped.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_J5XJ38HCnj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images_transformed = train_images_reshaped.astype('float32') / 255\n",
        "test_images_transformed = test_images_reshaped.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPD1fM2oCnj3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare the labels"
      ]
    },
    {
      "metadata": {
        "id": "bC3cokIECnj4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels_categorical = to_categorical(train_labels)\n",
        "test_labels_categorical = to_categorical(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jo3_mFqgCnj5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels_categorical[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tdm8P1UgCnj7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Network summary"
      ]
    },
    {
      "metadata": {
        "id": "K1LuIyavCnj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5nqpR0xCnj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 7. Train the network"
      ]
    },
    {
      "metadata": {
        "id": "cwMyDOv3Cnj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Feed the training images and labels to the network.\n",
        "\n",
        "Two additional parameters need to be supplied:\n",
        "\n",
        "- epochs: how many times the network will look at the entire dataset. \n",
        "- batch_size: how many images will be put through the network at one time."
      ]
    },
    {
      "metadata": {
        "id": "JKLbmXBQCnj_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.fit(train_images_transformed, train_labels_categorical, epochs=5, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8EZvkqUwCnkB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 8. Test the network"
      ]
    },
    {
      "metadata": {
        "id": "u11Xy0TLCnkC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use the test set (which the network has not seen yet) to test how well the network will perform on images it has not seen yet:"
      ]
    },
    {
      "metadata": {
        "id": "aY6jI5luCnkC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network.evaluate(test_images_transformed, test_labels_categorical)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnUZVu2vCnkD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('test_acc; ', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjHL-Mi1CnkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}